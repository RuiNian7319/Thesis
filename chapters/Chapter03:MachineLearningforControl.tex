%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Machine Learning in Control
%
% 1. Reinforcement learning Q-learning algorithm
%  - Extension to of tabular methods to continuous processes using interpolation
%  - Can be extended further using neighbourhood information
% 2. Continuous control using deep reinforcement learning
% 3. Comparison of results with MPC on simple systems
% 4. Fault tolerant RL vs. traditional methods
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Introduce adaptive control with Q-learning.  Weakness is discretization, so then extend to continuous with interpolation for linear systems, and show extension to that.

To completely overcome discretization, introduce DDPG.

Then compare these methods with MPC. MPC usually wins.

Then do fault tolerant control where RL beats MPC in some systems

\section{Tabular Q-learning and its Application in Process Control}

\section{Continuous Control using Deep Reinforcement Learning}

\section{A Comparison of Optimal Control Techniques}

\section{Fault-Tolerant Control System}
